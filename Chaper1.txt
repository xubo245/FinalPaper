1. 引言
0.
自年代以来，生物信息学逐渐发展成一门XXXX的新兴学科。
生物信息学的目的是通过计算机手段，研究生命科学本质。
其中，基因测序技术是目前生物信息学中的重要研究分支。通过基因测序可以发现生物序列中的功能、结构和进化的信息，在疾病监测、生物医疗等领域有重要作用。
过去几年来，生物测序技术长足发展，尤其是二代测序。涌现了很多不同的测序平台（Illumina、Life Science等）【GATK论文开头】，也开发出了一大堆工具（BWA、SOAP、GATK等）【GATK开头】。
同时，数据量也暴涨了，使得计算资源成为瓶颈。传统的工具和计算方法已经无法满足。目前，在单节点环境下，数据提交到结果反馈的响应时间长达数周，目前的相关研究也主要面向降低响应时间这一方面。
当下，大数据技术和分布式计算技术的进步提供了新的方法。相比之前的方法，Spark具有更好的性能、并行度和容错性。研究使用Spark、Hadoop等大数据处理框架对基因数据分析算法进行优化加速，具有重要的现实意义。
本章的结构：先阐述近年来基因测序技术发展和面临的问题，分析Hadoop、Spark等大数据技术发展带来的契机，然后阐明本文的研究动机，最后列出本文的主要贡献和本文的组织结构。

1.1 基因测序技术的发展与应用
基因测序是一种新型基因检测技术，能够从血液或唾液中分析测定基因全序列，预测罹患多种疾病的可能性，个体的行为特征及行为合理，如癌症或白血病，运动天赋，酒量等。
随着测序技术和变异注释的不断进步完善，基因测序相关产品和技术已由实验室研究演变到临床使用。基因测序为个体提供连续基因大数据，是精准医疗的基础和重要实现途径，展现出了巨大的商业价值。
苹果公司创始人乔布斯和影星安吉丽娜・朱莉都曾采用基因测序方法希望抵御癌症的侵袭。
从其技术的发展来看，基因测序经历了三个发展阶段，一般称之为第一代、第二代和第三代测序技术。
第一代测序技术由20世纪70年代中期由Fred Sanger及其同事首先发明，因此又称为Sanger测序技术。其原理主要是运用化学降解法、双脱氧链终止法、荧光自动测序技术和杂交测序技术等传统的化学方法进行测序。
虽然Sanger测序的速度缓慢，吞吐量很低，但是其读长更长，准确性也更高，在进行小规模基因组测序时成本也更为低廉，使得该技术在当今仍然具有一定的实用价值。【Patel N, Ferns B R, Nastouli E, et al. Cost analysis of standard Sanger sequencing versus next generation sequencing in the ICONIC study[J]. The Lancet, 2016, 388: S86.】
第二代测序技术又称为高通量测序，其特点是读长短，吞吐量大。其原理是用雾化、超声波和聚合酶等方法将DNA片段化成几百碱基或更短的小片段，然后并行地对几十万到几百万条片段进行序列测定。二代测序高吞吐量的特点使其在目前得到了广泛的应用。
为了在分子打散后能够重新拼接到其原有位置，在测序之前需要先进行PCR扩增【Nature NGS】，直观地讲就是对原有的DNA分子进行复制，使得打散后的片段有一定的堆叠。【图示】
PCR扩增加大了数据处理阶段输入的数据总量。同时，在PCR扩增时容易引入碱基位点的错误，导致后续数据处理的数据清理、变异位点发现等阶段需要运用复杂的统计方法规避这些错误带来的影响。
因此，相比一代测序，二代测序在数据处理阶段需要更大的计算量。
对于目前具有重大商业价值的人类基因组测序技术，实际商用的测序深度（即扩增的倍数）一般在30X以上，一个人类基因样本的原始数据量达到400GB。数据处理成为整个流程中的主要瓶颈。
目前，国内外已经开发了大量对二代测序的数据进行处理分析的工具。其中序列比对的工具包括BWA、Bowtie【引用】，数据预处理工具Samtools、BCFTools等【引用Git】。Broad Institute开发的GATK【引用】是一套基于MapReduce的基因数据分析工具，目前已经逐渐成为业内标杆。
针对这些工具的优化工作一直是近年研究的热点，诞生出很多利用FPGA、向量化等加速方法。然而目前的计算速度仍然远不能满足需求。
举例来说，一台Illumina测序仪的生成速度，而使用这些机器在单机上的处理时间需要数天乃至数周。而商用产品，尤其是医疗产品对低延时有很高的需求，即从提交样本到获得结果的间隔时间。
由此可见，在提高数据处理过程的计算性能、降低延迟方面仍然需要进一步的研究。
三代测序旨在解决第二代测序在成本和准确度等方面的问题，其特点是单分子、高通量，在不需要进行PCR扩增的前提下进行高通量的测序。比较有前景的方法包括单分子荧光测序、纳米孔测序等。【Braslavsky I, Hebert B, Kartalov E, et al. Sequence information can be obtained from single DNA molecules[J]. Proceedings of the National Academy of Sciences, 2003, 100(7): 3960-3964.】【Clarke J, Wu H C, Jayasinghe L, et al. Continuous base identification for single-molecule nanopore DNA sequencing[J]. Nature nanotechnology, 2009, 4(4): 265-270.】
目前三代测序还处在研究阶段，其准确度还远没有达到实用的标准。
在目前的基因测序产品中，核心手段是对人类测序数据进行变异位点检测。
其中典型的应用像Gene Panel流程，是通过检测比较病人癌细胞基因和正常组织细胞基因中的变异位点，依此作为病人使用靶向药物和其他治疗方案的重要参考。
在当前的竞争环境下，各大公司可能同时使用数条不同的流程应对各种复杂的应用场景。流程的开发成本很高，针对特定流程的优化工作难以复制。
（提及1000Gene？）

1.2 大数据处理技术的发展
二代测序的数据分析过程本质上可看做是一个大数据处理的过程。当下大数据处理技术的蓬勃发展为该过程的优化加速提供了新的契机与手段。
进入新世纪以来，互联网技术的发展使得网络上的数据总量呈现出爆炸性增长的趋势。如何从海量的半结构化数据中挖掘用户感兴趣的内容，为用户提供广告、推荐等个性化服务成为大数据技术发展的重要推动力。
大数据时代主要面临的挑战包括数据存储和分布式计算。前者是指海量的非结构化或半结构化数据（文本、网页等）的存储以及容错，后者是指在有限时间内使用多台机器对大规模的数据集进行遍历和分析。
针对这两个问题，Google在2003到2006年期间发表了三篇影响深远的论文：MapReduce、GFS和BigTable。【1 2 3】
开源社区借鉴Google论文中的方法，开发了MapReduce和GFS的开源实现Hadoop，并且基于MapReduce计算框架开发了Hive、Pig等数据分析框架，形成了庞大的Hadoop生态圈。【图】
MapReduce框架极大地简化了用户使用Hadoop进行分布式程序的编程过程，只需要对Map和Reduce两个原语进行实现，而不需要关心底层的数据交换、网络通信、负载均衡等问题。
当一个任务被提交到MapReduce上时，Map阶段会先将任务拆分成多个子任务，调度到多台机器上执行，然后根据Reduce的规则对局部结果进行归并。【图】
然而Hadoop的计算框架仍然存在一些明显的缺陷。首先是很多复杂的计算过程很难用Map和Reduce这种简单的原语来描述，其次是其计算的中间结果都放在HDFS上，带来了大量的磁盘读写开销。
针对Hadoop中存在的这些问题诞生了很多优化方案和项目，其中最著名的当属UC Berkeley开发的Spark。目前Spark已经成为Apache的顶级项目，因此又称为Apache Spark。
Spark在Hadoop的生态系统中属于与MapReduce同一层级的分布式计算框架。它基于内存计算的特性带来了比Hadoop快10倍到100倍的性能，同时当节点出现问题时事件重演的代价远低于MapReduce。
Spark使用弹性分布式数据集（Resilient Distributed Dataset, RDD）的概念封装数据的输入和数据处理，并且在RDD上提供了map、reduce、union、groupBy等上百种操作原语，极大地增强了MapReduce对数据处理过程的表述能力。
Spark使用有向无环图（Directed acyclic graph, DAG）来表示计算的每个阶段之间RDD的依赖关系，当有个别子任务出现错误时，根据DAG图对计算进行局部事件重演，显著提高了计算的容错性，降低了错误恢复的成本。

1.3 研究动机

之前提到，二代测序流程中产生的原始数据量非常庞大，使得数据处理成为流程中非常耗时的一环。
近年来随着基因测序技术逐渐用于精准医疗等领域，对人类基因组的测序的需求不断提升，且具备相当的商业价值。
相比一般用于研究的病毒、细菌的基因，人类基因序列的长度更长，需要的存储和计算量更大。
而目前开发的基因数据处理工具大多以单机多线程的工具为主，无法满足当前业内对大规模人类基因数据分析高吞吐、低延时的需求。
另一方面，目前基因测序的流程呈现出多样化的态势，不同公司针对不同应用会使用多种流程。使得开发多条流程的工作量较大，且很多基于特定流程的优化工作难以被复制。

基因数据分析本质上是一个大数据处理的问题，因此非常适合使用分布式计算技术进行并行和加速。
近年来大数据技术的蓬勃发展催生了Hadoop、Spark等更可靠、更成熟的分布式计算框架，在计算性能、容错性和大规模部署能力上有了质的提升。
使用Spark对基因数据分析流程进行优化和加速，能够解决目前人类基因测序产品中高延迟的问题，有巨大的实用价值。
Spark、Hadoop环境还非常易于在研究机构、公司的机房环境部署，可以让基因测序流程不再依赖于超算中心进行数据处理，降低了行业的门槛。
此外，如果能够根据基因数据处理算法的特点，将具体的基因数据处理算法集成为一体的框架，可以大大降低新流程的开发成本，同时带来更大的优化空间。
因此，本文的主要工作就是基于Spark平台，开发面向基因组数据分析的编程框架。利用Spark高性能、高伸缩性、高可靠性的特点，实现对基因数据分析流程的加速。
同时，框架集成了常见的基因数据处理算法，大大降低了流程的开发成本，并基于框架实现了对流程整体的优化。

1.4 本文主要贡献
本文通过分析主要的基因数据分析算法，针对不同算法提出了其在Spark环境下的并行策略，并将Spark上的算法实现抽象为API，形成面向基因数据分析的编程框架。论文的主要工作如下：
（1）总结当前主流的基因数据分析算法和工具，提出将主流的基因数据分析算法分为序列比对、数据清理和变异位点发现三类。深入分析了各个算法的可并行性和的并行方式，并总结了已有优化工作中存在的问题和瓶颈。
（2）在Spark平台上对各个基因数据分析算法进行实现。结合Spark程序的一般特点，在算法实现中避免使用Shuffle操作，整体上提高了程序性能。将算法抽象成API，方便用户通过函数调用的方式构建自己的流程。
（3）实现了面向基因数据处理流程的流程执行引擎，提出基于DAG的流程定义方法。通过执行引擎解析流程中各步骤的数据依赖，决定步骤的执行顺序。该方法适用于所有类似的流程定义，具有一定的普适意义。
（4）基于对一些算法中相同计算模式的分析，基于执行引擎实现了步骤间冗余计算消除优化，进一步提升了程序性能。

1.5 本文结构
本文总共分为六章。
第一章概述了课题的研究背景。以基因测序技术的发展历程及商业前景以及大数据技术的发展进步，凸显本课题的研究动机和意义，并介绍了本课题的研究内容和主要贡献。
第二章介绍了技术背景和相关研究。首先将典型的基因数据分析流程分为序列比对、数据清理和变异位点发现三个部分，对每部分的作用和常见方法进行简单概述。然后介绍目前已有的对流程的优化加速工作，分析其方法的优点以及存在的问题。
第三章对主流的基因数据处理算法和工具的原理和实现进行详细介绍，并分析其可用并行方式，为后文讲述算法在Spark平台上的实现进行铺垫。
第四章介绍了基因数据分析的编程框架SparkSeq的设计与实现。框架结合Spark程序的特性，高效地实现了多种基因数据处理算法，并抽象成API的形式，方便用户调用进行二次开发。此外，本章还将介绍基于DAG的流程执行引擎的设计，以及基于执行引擎的流程间冗余计算消除优化。
第五章以典型基因数据分析流程DNASeq Best Practice为例，对框架进行全面的正确性、性能和资源使用效率的测试。此外，还在天河二号上进行了上机测试，以对框架的性能和扩展性进行全面评估。
第六章对全文进行总结，并提出未来可能的研究方向。