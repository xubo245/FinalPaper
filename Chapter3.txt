第三章
Spark适用于进行快速、可靠的大数据分析。基因数据分析流程的数据和计算量规模也符合Spark的承载范围。不过相比于一般的Spark数据处理过程，基因数据处理算法更加复杂，不同的基因数据算法采用的并行方式不尽相同。本章将对框架中集成的几种算法的具体流程和并行方式进行分析，讨论在Spark上的实现方式。

3.1 BWA mem
BWA mem算法是DNA序列比对中常用的算法，支持对Pair-end数据和Single-end数据的比对。该算法能够高效而精确地比对100-500长度的较长序列，逐渐成为最流行的Read比对算法。
BWA mem算法采取了seed-and-extends的方法进行序列匹配，即先找到Read中与参考基因组能够精确匹配的最长子序列作为seed，然后向两边延伸的匹配方法，主要包括如下步骤：
（1）首先加载参考序列和相应索引。索引可以在测序之前提前建立，其作用是加速短序列精确匹配的过程。
（2）加载一定数量的Read数据到内存当中，成为一个Chunk。默认的Chunk大小是100000bp，该长度可由用户通过参数指定。每条Read单独进行比对。
（3）随机选取Read中的k-mer，根据索引查找到序列中的对应位置，然后向两个方向进行精确匹配，得到最长的精确匹配子序列，作为seed。seed之间可能有重叠，但是不会有包含关系。
（4）将临近或重叠的seed组合在一起形成Chain，一方面减少算法的查找空间，另一方面允许比对结果中有一定的mismatch，从而提高比对的质量。由于seed可能会遍布在reference的各个位置，因此一条Read可能会产生多条Chain。
（5）基于Smith-Waterman算法，向Chain的两端进行扩展，基于编辑距离计算该结果的质量分数，选取最终的比对结果。如果没有合适的结果，则Read被标记为Ummapped。
（6）生成position、Cigar、标志位和比对质量分数等信息，结合用户指定的参数生成SAM格式的记录。
BWA mem算法的重要特性之一是每条Read（在Pair-end中是一对Read）的比对过程相对独立。理论上所有的Read的比对过程都可以并行执行，目前BWA的多线程并行处理方式就是将一条Read分配给一个线程进行比对处理。。
在分布式环境下，每台机器运行一个或多个BWA进程，在比对过程中不需要进行进程间通信，因此可以采用直接将输入数据以Read为单位进行划分，每个划分分别运行BWA mem算法，最后将结果合并的方法。HugeSeq和Churchill中均采用了这种方法实现了多进程并行。
经过对BWA代码的进一步研究发现，对于Pair-end的数据，BWA会对于一个Chunk内的Read的insert size字段进行均值和方差进行统计，以对距离过远的mate重新比对【Li H. Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM[J]. arXiv preprint arXiv:1303.3997, 2013.】，而Chunk划分不同可能导致均值和方差不同，从而对比对结果产生轻微影响。
如果要保证Chunk的切分和单进程相同，可以预先设定Chunk的大小，在划分FASTQ文件时根据Chunk大小决定切分的位置，保证每个划分都是Chunk大小的整数倍。该遍历过程只能串行执行，且会带来较大的磁盘开销。
不过因为Chunk大小本身是一个参数，且Chunk内的统计值不会随划分变化产生明显的波动，因此可以认为该影响可以忽略不计。
该算法在Spark上的并行方式如下【图】：
（1）通过hadoopAPI接口，可将FASTQ文件格式化地读取成FASTQ记录的RDD，并自动在多机上划分为多个partition。
（2）对于pair-end数据，需要将读取两个FASTQ文件得到的记录以成对的形式放在一个partition中，采用的方式是以FASTQ描述行中的Read Name为键进行groupBy操作。groupBy产生的RDD的元素是成对的FASTQ记录。
（3）使用mapPartition操作，在partition内的成对FASTQ记录执行BWA mem算法，得到包含SAM记录的列表。

3.2 Picard Mark Duplicate
Piard Mark Duplicate适合对Pair-end的DNA数据进行冗余去除，常用于Data cleaning的开始阶段。算法依赖于Mapping阶段得到的每条Read所属的contig、在contig上的position、标志位等信息。
算法按照如下规则进行冗余Read的标记和去除：
（1）算法引入了PairEnds和Fragment两个概念：PairEnds由两条成功比对的Read组成。如果Read没有mate或者其mate是unmapped的，那么这条read是一个fragment。
（2）如果一个PairEnds中两条read的contig、position和匹配方向与另一个PairEnds完全相同，则认为两个PairEnds存在冗余。算法比较两对PairEnds中Reads的比对质量分数，将质量较低的一对标记为冗余。
（3）如果一个Fragment的reference contig、position和匹配方向与另一个Fragment完全相同，则认为两个Fragment存在冗余。算法将比对质量分数较低的fragment标记为冗余。
（4）另外，如果一条Fragment与一对PairEnds中的某一条read的reference contig、coordinate和方向完全相同，则将这条Fragment标记为冗余。
Picard中集成了Mark Duplicate的串行实现。在使用之前一般需要用Samtools等工具先对输入的SAM/BAM文件进行排序。算法经过多次遍历得到文件中冗余read的下标。
在第一次遍历中，将所有Read组织成PairEnds和Fragment的形式，以特定格式记录到文件中，同时在结构中保存Read在文件中的下标。将一条Read加入缓存中，当遍历到它的mate read时将其从缓存中取出，组成一个PairEnds。没有mate的read被标记为fragment。在写入文件时保证写入具有一定的顺序。
然后遍历PairEnds和Fragments，之前的排序保证了可能冗余的数据在文件中是相邻的，将可能冗余的数据组织成一个Chunk，最后得到冗余Reads在原始文件中的下标集合。
最后再次遍历原始文件，对冗余的Read进行标记或去除。
目前业内还没有针对Mark Duplicate算法的并行方法。因为成对的read在文件中相隔的距离可能很远，因此无法直接使用数据划分的方法进行并行。
HugeSeq中使用染色体切分的方法，在每条染色体上分别运行Mark duplicate算法，使得映射在不同染色体上的mate read无法被正确处理。Churchill中采用按照interval切分的方法，并且引入artificial chromosome的概念，通过在切分时加入冗余计算来保证去冗余和后续计算的完整性。
在本文中，我们基于Spark提供的数据操作原语进行并行实现，并且保证了和串行算法结果的一致，具体步骤如下：
（1）过滤去除所有unmapped以及带有secondary、supplementary标志的read。
（2）在SAM Record为元素的RDD上，以read name为键使用groupBy操作。如果有两个同名的read被分在一组，则构成一个PairEnds，如果没有，则作为一个Fragment。
（3）通过map操作，从PairEnds和Fragment组织成ReadPairInfo的结构，ReadPairInfo中保存了Read的引用、质量分数、mapping位置等信息。
（4）根据ReadPairInfo生成签名，签名内容包括两条read的contig、position和匹配方向。如果是一个Fragment，那么签名只包括一条read的信息。以签名为键进行groupBy操作，使得冗余的PairEnds和冗余的Fragment被分到一个组中。
（5）在组中选择质量分数最高的PairEnds/Fragment，其余作为冗余去除。通过flatMap操作将RDD重新转化为以SAM Record为元素的RDD。
（6）由于此前PairEnds和Fragment的签名一定不相等，导致符合情况（4）的冗余仍然存在。为此再将所有的Read单独构建ReadPairInfo，以签名为键进行groupBy操作，使得fragment和PairEnds中与之重合的一条或多条被分在一个组中。
（7）对于每个分组，通过查看Read的Flag确定其是否属于一个PairEnds中的一条。如果一个分组中包含这种Read，则去除所有的Fragment。

3.3 Indel Realignment
在介绍Indel Realignment算法之前，需要对GATK框架进行整体说明。
GATK是一个NGS数据处理框架，其中集成了多种常用的基因数据处理工具。框架中的工具以map-reduce为编程模型，将整个数据处理阶段看做对多个数据单元的处理。
map阶段是对一个数据单元进行处理分析，然后在reduce阶段将分析结果merge到全局的结果。于分布式计算框架Map-Reduce不同，GATK中的map-reduce并不表示数据处理是可并行的，具体的并行方式由各个工具根据所包含的算法自行实现。
常见的数据单元主要有Read和Pileup两种。以Read为单元的map阶段需要传入的数据包括Read在SAM/BAM中记录的数据，Read对应的reference序列以及附近的已知变异位点信息。以Pileup为单元的map阶段需要传入的数据包括Reference上的一个位点、该位点的已知变异位点信息以及该位点上的Pileup。Pileup定义为覆盖该位点的所有Read在该位点处的碱基、质量及Cigar等信息【图】。
Reduce阶段将map的返回值通过某种方式进行合并，适用于一些需要对全局数据进行统计的工具（比如BaseRecalibrator）。
了解了GATK工具的一般框架，接下来开始对Indel Realignment算法的讲解。Indel Realignment算法分为两步：首先使用GATK中的RealignerTargetCreator工具找到需要进行局部重比对的区域，再使用IndelRealigner工具对区域中的Read进行重新比对。
RealignerTargetCreator是一个以Pileup为计算单元的工具。如果当前位点是一个已知的变异位点，或者在Pileup中有Read在该位置表现为Insertion或Deletion，则将该位置视为一个Event。算法在Reduce阶段将临近的Event连在一起，形成多个target region。然后使用IndelRealigner工具对每个target region内的Read进行重新比对。
IndelRealigner是一个以Read为计算单元的工具。首先读取上一步得到的target region，将与target region有重叠的read放在一个集合当中。在集合内根据已知位点和read中的indel生成多个候选indel，然后在假设某个候选indel为真的情况下，在不考虑Cigar的情况下对read进行偏移调整，将调整后read与reference不一致位点的质量分数之和作为这个候选indel的负面评分，最终选择惩罚评分最低的indel作为最佳indel，进而调整read的比对位置以及比对质量分数等信息。
RealignerTargetCreator中map操作用于判定pileup是否会生成一个Event，多个map操作可以并行。但是Reduce阶段需要使用树形归并的方法，将临近位点的map结果构建成一棵树，每棵树最终会产生一个target region。【图】
这种局部数据相关的特点不适合在Spark中使用细粒度的方式进行并行。更好的方法可以采用粗粒度的并行方式，让一个任务每次处理一段连续区域的pileup，这样仅在区域的左右边缘位置可能需要临近区域的信息。【图】
为了进一步避免任务间的数据交换，可以为每个region添加一定长度overlap，让每个任务会进行冗余的map计算。按照实际经验来看，target region的长度一般均在100bp以下。因此在每个region足够长的情况下，只要引入少量的额外计算，就可以完全消除任务间的数据依赖。【图】
IndelRealigner的map阶段需要在获取一个target region中全部read之后再进行清理工作，因此不适合在map阶段直接并行。参考RealignerTargetCreator中粗粒度的并行方式，将Read数据按照reference的区域分成多个partition，在添加一定长度的overlap之后，一些read也会被分到不同的任务道中，因此可以保证每个任务都可以获取负责范围内的target region中的所有read，从而保证了每个target region至少有一个任务能够正确计算。
因此，我们在Spark中使用如下方法对算法进行实现：
（1）读取Reference的序列名称、序列长度等信息，生成分区信息。每个分区的两端留出一定长度的overlap。
（2）将Reference、已知位点和Read数据按照分区信息得到所属的partitionId，使用groupBy操作划分到多个partition当中。其中位于overlap中的数据需要被复制并赋予不同的key，使其可以被划入临近的partition。
（3）在partition内部遍历Pileup，找到需要重新比对的target region。
（4）在同一个partition内

3.4 Base Quality Score Recalibration
Base Quality Score Recalibration算法的原理是对整体数据进行统计，构建位点错误与观测特征的共现模型（covariation model）当某个位点符合特征对应的错误率越高，说明该位点的可信度越低，由此重新评估Read中每个位点的质量分数。
算法首先使用BaseRecalibrator工具对所有Read进行质量统计，得到质量分数相关的统计表；然后使用PrintReads工具，根据统计信息对所有Read的质量分数进行调整。
BaseRecalration以Read为数据单元。对于每条Read的处理步骤如下：
（1）对Read的位点进行遍历，记录序列与Reference发生mismatch的个数。
（2）如果一条Read上存在mismatch，则使用HMM模型重新计算本条Read每个位置上的比对质量（Per-Base Alignment Qualities, BAQ ) 。
（3）如果Read与序列发生的mismatch不属于已知位点，则视为一个测序错误（Error）。根据Error的种类（snp、insertion或deletion），结合BAQ生成每种类别的错误指数。
（4）根据共现模型，将错误指数累加到对应的特征中。
完成Read的遍历之后，根据累加的错误指数和特征的观测次数重新估计整个数据集中Read的质量分数，生成BQSR表。PrintReads工具将读取这份报告，在遍历所有Read的同时对Read逐个进行转化。
BaseRecalibrator的计算过程本质上是一个计算局部结果再累加的过程，其中局部结果的计算式以Read为单位进行的，Read之间不存在干扰。基于以上特征，可以将Read划分在多个任务当中，然后生成局部的Error统计进行归并。局部结果的归并方式是累加，对计算的先后顺序没有要求，因此可以使用树形归并的方式进行。在得到归并的Error统计之后，再统一生成BQSR表。
